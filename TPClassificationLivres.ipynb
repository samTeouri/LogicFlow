{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ5vas82illV"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/TPClassificationLivres.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "---\n",
        "# Classification de commentaires de livres (en français)\n",
        "\n",
        "## Collection de données de critiques de films\n",
        "Le tp utilisera l'ensemble de données issues de\n",
        "[French Book reviews](https://www.kaggle.com/datasets/abireltaief/books-reviews) que vous devez télécharger.\n",
        "\n",
        "Ce fichier CSV contient presque 10000 commentaires sur des livres, leurs notes, et l'avis (positif, négatif ou neutre)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8vpRECVlCda"
      },
      "source": [
        "---\n",
        "Vous vous baserez sur la solution à *[Détection de \"sentiments\"](https://github.com/EmmanuelADAM/IntelligenceArtificiellePython/blob/master/SolutionTPDetectionDeSentiments.ipynb)*.\n",
        "\n",
        "Vous adapterez le code présent pour traiter le texte en français.\n",
        "Simpement, les \"stopwords\" seront chargés ainsi :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "##import pour la creation de tokens\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "\n",
        "##import pour la gestion de ponctuation\n",
        "from string import punctuation\n",
        "\n",
        "##import pour une collection spécifique : counter\n",
        "from collections import Counter\n",
        "\n",
        "##import pour les réseaux de neurones :\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "##import classique pour les tableaux efficaces\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_PXHysu6T9Vv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2-21PcrPlCdb",
        "outputId": "3656e1a9-91cd-4585-d622-c8a766e2233b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words('french'))\n",
        "\n",
        "Series = pd.core.series.Series\n",
        "DataFrame = pd.core.frame.DataFrame\n",
        "\n",
        "df = pd.read_json(\"hf://datasets/Abirate/french_book_reviews/french_books_reviews.jsonl\", lines=True)\n",
        "reader_reviews:Series = df[\"reader_review\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9QOWf-elCdi"
      },
      "source": [
        "---\n",
        "A partir de la colonne 'reader_review' plusieurs classements sont possibles :\n",
        "- soit le classement de valeurs entre -1 et 1 (ce qui correspond à la colonne 'label')\n",
        "- soit le classement par une note entre . et 5 (ce qui correspond à la colonne 'rating')\n",
        "\n",
        "*N.B. la fonction d'activation sigmoid pren ses valeurs dans [0,1], l'activation en utilisant la tangente hyperboliquye 'tanh' prend ses valeus dans [-1, 1]*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rpoDE5M2lCdj",
        "outputId": "f2057f3d-b278-4d68-abc6-921294348012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9658/9658 [00:00<00:00, 11146.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb de mots cles trouves dans les repertoires :  33512\n",
            "les 10 premiers mots cles du vocabulaire (et leur nb d'apparition dans les exemples)  : \n",
            "premier : 666, roman : 2083, aborder : 32, thèmes : 72, lourds : 5, inceste : 6, enfance : 141, martyre : 1, fait : 1339, audace : 10, brio : 22, \n",
            "les 10 mots cles les plus utilises :  [('plus', 2435), ('livre', 2380), ('cette', 2223), ('tout', 2097), ('roman', 2083), ('histoire', 1978), ('bien', 1853), ('très', 1814), ('fait', 1339), ('comme', 1273)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def clean_doc(doc:str)->list:\n",
        "    \"\"\"retourne la liste de mots clés inclus dans le texte doc\n",
        "    qui ne font pas parti des stop_words\"\"\"\n",
        "    # split into tokens by white space\n",
        "    tokens = wordpunct_tokenize(doc)\n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "    # filter out stop words\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    # filter out short tokens\n",
        "    tokens = [word for word in tokens if len(word) > 2]\n",
        "    return tokens\n",
        "\n",
        "def add_doc_to_vocab(reader_review:str, vocab:Counter):\n",
        "    \"\"\"cumule dans la liste vocab les mots de la review\n",
        "    (1 seule occurrence par mot dans vocab)\"\"\"\n",
        "    # clean doc\n",
        "    tokens = clean_doc(reader_review)\n",
        "    # update counts\n",
        "    vocab.update(tokens)\n",
        "\n",
        "def build_voc(serie:Series, vocab:Counter):\n",
        "    \"\"\"ajoute au dictionnaire vocab les mots cles de 90% de la serie de données\"\"\"\n",
        "    i=0\n",
        "    nb = int(serie.size)\n",
        "    # walk through all files in the folder\n",
        "    for i in tqdm(range(nb)):\n",
        "        # add doc to vocab\n",
        "        add_doc_to_vocab(serie[i], vocab)\n",
        "\n",
        "# creer un vocabulaire (liste de mots clés associés à leurs occurrences)\n",
        "vocab:Counter = Counter()\n",
        "build_voc(reader_reviews, vocab)\n",
        "# afficher le nb de mots cles trouves\n",
        "print(\"nb de mots cles trouves dans les repertoires : \", len(vocab))\n",
        "print(\"les 10 premiers mots cles du vocabulaire \\\n",
        "(et leur nb d\\'apparition dans les exemples)  : \\n\", end='')\n",
        "i:int=0\n",
        "for (mot,count) in vocab.items():\n",
        "    print(mot,':',count,end=\", \")\n",
        "    i = i+1\n",
        "    if i>10:break\n",
        "# afficher les 10 mots cles les plus utilises\n",
        "print(\"\\nles 10 mots cles les plus utilises : \", vocab.most_common(10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copie de TP_DeepLearningM1TNSI.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}